## EXTRA IDEAS:

- add a way for the user to test their current values.md file by getting various leading LLMs to answer dilemmas using this file as context vs. not using it

- add a way for the user to see which LLM their values are most aligned to natively i.e. which LLM makes similar choices without a system prompt

- explore the different LLM behaviour depending on whether we are asking it to theoretically solve the dilemma OR we tell the LLM that it is actually guiding the real choice / situation now (and provide tools / function calls as a way of action - faked but LLM doesn't know)